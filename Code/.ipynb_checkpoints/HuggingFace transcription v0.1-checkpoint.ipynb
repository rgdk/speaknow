{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a225d6f2-bb49-40d3-bf27-7856d11990df",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfa6acd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import deepspeech\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n",
    "\n",
    "_ =load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d913598-7af1-4605-9d0f-7fa4e99332a2",
   "metadata": {},
   "source": [
    "#### Script Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3a986d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the directory containing the MP3 files\n",
    "audio_folder_dir = '../Data/audio'\n",
    "huggingface_transcripts = \"../Training/chatgpt_transcripts\"\n",
    "\n",
    "# List all files in the audio directory\n",
    "audio_files = os.listdir(audio_folder_dir)\n",
    "mp3_files = [file for file in audio_files if file.endswith('.mp3')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da2a8cd-03de-48c0-ba0e-29a0bb85ebba",
   "metadata": {},
   "source": [
    "#### Convert mp3 files to wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fec1e75-a98b-423e-9fac-f973c08c7192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp3_to_wav(audio_folder_dir, audio_folder_dir):\n",
    "    # Loop through all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Check if it's an mp3 file\n",
    "        if filename.endswith(\".mp3\"):\n",
    "            # Define input and output filenames\n",
    "            input_file = audio_folder_dir + \"/\" + filename\n",
    "            output_file = os.path.splitext(input_file)[0] + \".wav\"\n",
    "    \n",
    "            # Load the audio segment\n",
    "            sound = AudioSegment.from_mp3(input_file)\n",
    "    \n",
    "            # Export the audio as wav\n",
    "            sound.export(output_file, format=\"wav\")\n",
    "    \n",
    "            print(f\"Converted {input_file} to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0aede1-4163-4cf3-9f81-c29e590d78ad",
   "metadata": {},
   "source": [
    "#### Executing the HuggingFace Wav2Vec2Tokenizer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9429deeb-392a-4859-a602-7184f36699da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcription job completed\n"
     ]
    }
   ],
   "source": [
    "def generate_transcripts_hf(output_dir):\n",
    "    # Importing Wav2Vec pretrained model\n",
    "    tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "    model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "    \n",
    "    for audio_file in wav_files:        \n",
    "        if audio_file.endswith(\".wav\"):\n",
    "            audio, rate = librosa.load(folder_path+\"/\"+audio_file, sr = 16000)\n",
    "            \n",
    "            input_values = tokenizer(audio, return_tensors = \"pt\").input_values\n",
    "    \n",
    "            logits = model(input_values).logits\n",
    "    \n",
    "            prediction = torch.argmax(logits, dim = -1)\n",
    "    \n",
    "            # Passing the prediction to the tokenzer decode to get the transcription\n",
    "            transcription = tokenizer.batch_decode(prediction)[0]\n",
    "    \n",
    "            # Create text file with the same name as the WAV file, but with .txt extension\n",
    "            text_file_path = os.path.join(huggingface_transcripts, os.path.splitext(audio_file)[0] + \".txt\")\n",
    "            with open(text_file_path, \"w\") as text_file:\n",
    "                text_file.write(transcription)\n",
    "            text_file.close()\n",
    "\n",
    "print(\"transcription job completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3d6514-51b5-4787-b64f-ee120318d141",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
